{"path":"docs/学校课程/归档课程/大数据/课件/12 MapReduce数据挖掘基础算法 (III).pdf","text":"MapReduce数据挖掘基础算法(III) 摘要 ¨ 频繁项集挖掘算法 ¨ 应用案例 2 频繁项集挖掘 ¨ 关联规则或频繁项集 ¤ 频繁项可以看作是两个或多个对象的“亲密”程度，如果同时出现的 次数很多，那么这两个或多个对象可以认为是高关联性的。当这些高 关联性对象的项集出现次数满足一定阈值时即称其为频繁项。 ¨ 经典实例：购物篮分析 ¤ 啤酒和尿布 3 频繁项集 ¨ m个项的集合： I = {𝐼!, 𝐼\", … , 𝐼#} ¨ n个事务的数据库：D = {𝑇!, 𝑇\", … , 𝑇$}，其中𝑇%是I的非空子集。 ¨ 关联规则：𝑋 ⇒ 𝑌 ，其中X，Y是I的子集，并且𝑋 ∩ 𝑌 = ∅ ¨ 关联规则的𝑋 ⇒ 𝑌的支持度是指D中事务包含𝑋 ∪ 𝑌的百分比，置 信度是指包含𝑋的事务中同时包含Y的百分比，也就是条件概率 P(Y|X) ¨ 如果某一规则𝑋 ⇒ 𝑌的置信度和支持度都高于某个阈值，那么可 以认为X，Y具有关联性。 4 频繁项集 ¨ 把满足上述条件的X，Y组成一个项集A，则可以认为，数据库D 中包含A的事务超过了某个最小支持度。而所谓频繁项集挖掘， 就是将所有满足项数为某个固定整数k，且支持度高于某阈值的 项集计算出来。 ¨ 经典算法：Apriori，FP-growth，SON等。 5 Apriori算法 ¨ 通过多轮迭代的方法来逐步挖掘频繁项集 ¨ 先验原理： ¤ 频繁项集的任何非空子集都是频繁的。 ¤ 非频繁项集的任何超集都是非频繁的。 6 Apriori算法 L!={frequent 1-itemsets}; For (k=2; L\"#! ≠ null; k++} do begin //多轮迭代过程 C\"=apriori-gen(L\"#!); //候选k-项集 for each transaction t ∈ D do begin C$ = subset(C\", t); //生成子集 for each candidate c ∈ C$ do c. count ++; //计算实际的支持度 end L\"={ c= C\" | c. count ≥ minsup } end Answer = U\"L\" 7 Apriori算法 8 Apriori并行化算法设计 ¨ 主进程扫描事务数据库，从原始数据集中产生候选1-项集 ¨ 由候选1-项集与原始数据集进行对比，算出每个项集的支持度，这些支持度与 程序中给定的支持度进行对比，得出频繁1-项集 ¨ 由频繁1-项集产生候选2-项集，并通过与原始数据集比较得到频繁2-项集 ¨ 逐次迭代直到产生候选k-项集，候选k-项集与原始数据集对比，如果存在频繁 k-项集，则继续迭代执行；如果不存在，则最终得到频繁(k-1)-项集 9 Apriori并行化算法设计 ¨ 第一轮迭代：计算频繁1-项集 ¨ Map阶段 ¤ 输入key：事务数据库每行首字符相对于文本文件的首地址偏移；输入value：存储在事务数 据库文件中的一行数据 ¤ 输出key：候选1-项集 输出value：1 Map Task: For each transaction t in Si Map(line offset, t) For each item I in t Emit (I, 1); End For each End Map() End For each End Map 10 Apriori并行化算法设计 ¨ Reduce阶段 ¤ 输出key：频繁1-项集；输出value：出现的次数 Reduce Task: Reduce(key2, value2) Sum = 0; While (value2.hasNext()) Sum += value2.hasNext(); End While If (Sum>=Minsup) Emit (key2, sum) //得到频繁1-项集 End If End Reduce 11 Apriori并行化算法设计 ¨ 第k轮MapReduce迭代：计算k-频繁项集 ¨ Map阶段 ¤ 输入<key,value>对为：事务数据分片中的每个事务数据。这个阶段会 从频繁(k-1)-项集得到候选k-项集，频繁(k-1)-项集存放在Distributed Cache中以便每个Map节点共享读取和使用。为了产生候选k-项集，包 括连接和剪枝过程。 ¤ 输出key为候选k-项集，value为其出现的次数。 12 Apriori并行化算法设计 Map Task: Read Lk-1 from HDFS file Ck = ap_gen(Lk-1) //self join连接过程 For each transaction t in Si Map(line offset, t) Ct = subset (Ck , t) //获取在原始事务数据中出现的候选项集 For each item c in Ct Emit (c, 1); End For each End Map() End For each End Map 13 Apriori并行化算法设计 ¨ Reduce阶段 ¤ 输出key：频繁k-项集；输出value：出现的次数 Reduce Task: Reduce(key2, value2) Sum = 0; While (value2.hasNext()) Sum += value2.hasNext(); End While If (Sum>=Minsup) Emit (key2, sum) //得到频繁k-项集 End If End Reduce 14 基于子集求取的频繁项集挖掘算法 ¨ 一个频繁项集F必然是D中某个事务的子集，即只要根据事务数 据本身就可以计算频繁项集。 ¨ 假设数据库为D，事务为T，项集大小为k ¤ 首先扫描数据库，对数据库中的每一个事务做如下操作：将该事务所 有大小为k的子集求出来(Mapper) ¤ 然后，统计输出所有子集的个数，如果某个子集的个数超过了某一阈 值S，那么就可以认为这个子集是频繁项集，将所有这样的子集输出 即可(Reducer) 15 基于子集求取的频繁项集挖掘算法 ¨ Mapper Class MiningMapper{ map(T){ //T为数据库中的一个事务 /** 求出T所有大小为k的子集 **/ /** 若T的项数小于k，则子集数为0 **/ Subsets = FindSubsets(T, k); for (i=0; i<Subsets.size(); i++) subset = Subsets.get(i) emit(subset, 1) } } 16 基于子集求取的频繁项集挖掘算法 ¨ Reducer Class MiningReducer{ reduce(key, value_list){ sum = 0; while(value_list.hasNext()) sum += value_list.next().get(); if(sum > minSupport) emit(key, sum); } } 17 SON算法 ¨ 有限扫描：最多两遍之内发现全部或者大部分频繁项集。只利用数 据抽样样本而不是全部数据集进行计算。 ¨ 基本思路：先采样部分样本，在其上运行Apriori算法，并调整相应 支持度阈值。采样得到的子数据集直接存入主存，之后扫描数据自 己不用再次进行I/O操作。 ¤ 例如选择1%的样本，支持度阈值为s/100 ¨ 抽样可能导致完整数据集上的频繁项在样本中不频繁(false negative)，样本中频繁但在整个数据集上不频繁(false positive) 18 SON算法 ¨ SON算法同时避免了false negatives和false positives，所带来的代 价是需要两次扫描。 ¨ 基本思想：将输入文件划分成1/p个块(p为样本占全部数据集的 比例)，将每个文件块作为一个样本，并执行Apriori算法。同样适 用p*s作为其阈值。将每个块找到的频繁项集放到磁盘上。 19 SON算法 ¨ 第一步：找到局部频繁项集 ¤ 一旦所有的块按此方式被处理，将那些在一个或多个块中被选中的频繁项 集收集起来作为候选频繁项集。注意，如果一个项集在所有的块中都不是 频繁项集，即它在每个块中的支持度都低于p*s。因为块数为1/p，所以，整 体的支持度也就低于(1/p)*p*s=s。这样，每个频繁项集必然会出现在至少一 个块的频繁项集中，于是，我们可以确定，真正的频繁项一定全在候选频 繁项集中，因此这里没有false negatives。 ¨ 第二步：找出全局频繁项集 ¤ 计算所有的候选频繁项集，选择那些支持度至少为s的作为频繁项集。 20 SON算法并行化 ¨ 第一个Map 函数：使用子集，并在子集上使用Apriori算法找出每个项集的频繁度。将支持度 从s降为p*s，输出(F,1)，F为该样本的频繁项集。 ¨ 第一个Reduce函数：产生那些出现一次或多次的key（即项集），输出候选项集。 ¨ 第二个Map函数：接受第一个Reduce函数的所有输出和输入数据文件的一部分，每个Map任务 计算每个候选项集在当前数据集上出现的次数，输出为(C,v)组成的集合，其中C是一个候选集， v是C在本Map任务所分配数据上的支持度。 ¨ 第二个Reduce函数：将分配的项集作为Key，并将关联的值求和。最终得到每个Reduce任务所 分配的每个项集在整个数据集上的全部支持度。那些值求和后不低于s的项集是整个数据集上 的频繁项集，Reduce任务会将这些项集及其计数值输出。 21 应用领域 ¨ 购物篮分析 ¨ 信用卡交易分析 ¨ 电话呼叫模式分析 ¨ 医疗保险欺诈识别 ¨ 电信服务交易分析 ¨ 大型在线零售商的每日/周交易分析 ¨ …… 22 基于关联规则挖掘的图书推荐算法 ¨ 基于Apriori基本算法实现 ¤ 采用类似单词计数的过程并行扫描数据库，找出满足最小支持度的1- 频繁项集L1 ¤ L1通过自身连接产生2-候选项集C2，采用候选项集支持度的并行化统 计方法统计C2的支持度，行成2-频繁项集L2；以此类推，L2产生L3，如 此迭代循环，直到完成k-频繁项集的计算。 23 基于关联规则挖掘的图书推荐算法 ¨ 数据获取：豆瓣读书网站API ¤ 获取书籍信息 ¤ 获取特定书籍的所有评论 ¨ 算法实现： ¤ 计算每本图书的支持度 ¤ 统计2-频繁项集中每个元组的支持度 ¤ 计算每个2-频繁项集元组中图书A到图书B的置信度 24 图书推荐系统 25 全文搜索引擎算法设计实现 26 What happens after you press enter? 体系结构 27 DocumentsQuery Hits Representation Function Representation Function Query Representation Document Representation Comparison Function Index offlineonline document acquisition (e.g., web crawling) 功能 28 Documents Inverted Index Bag of Words case folding, tokenization, stopword removal, stemming syntax, semantics, word knowledge, etc. 简单的倒排索引示例 29 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 3 1 1 1 4 1 1 1 2 1 1 2 1 blue cat egg fish green ham hat one 1 1 1 1 1 1 2 1 blue cat egg fish green ham hat one 1 1red 1 1two 1red 1two one fish, two fish Doc 1 red fish, blue hat Doc 2 cat in the hat Doc 3 green eggs and ham Doc 4 3 4 1 4 4 3 2 1 2 2 1 12 MapReduce’s Role… 30 Not so good … 1.must have sub-second response time 2.for the web, only need relatively few results Indexing Problem Retrieval Problem Character Description Suitable? Perfect ! 1.scalability 2.relatively fast 3.batch operation 4.updates may not be important 5.crawling is a challenge in itself 小百合全文搜索引擎设计与实现 ¨ 工作流程 ¤ Web page爬取和挖掘 ¤ 建立索引 ¤ Web信息检索接口 31 引自：黄宜华，顾荣 《MapReduce》课程讲义 2011年 32 Response Query String Web Page 0 Web Page 1 Web Page n Crawl && Info Mining Formated Files /Content /Vice Info Inverted Index && Ranking <DID, Rank> …… <DID, Rank> …… <DID, Rank> …… JSP Page Split Term0,Term1…Term n Search & Merge Target DID Result List Title Context Author URL Hot token 1 token 0token n Index For Indices Crawler Web Retrival Map/Reduce Crawler策略：DFS Post 1 Post n Post 0 Title in here BBS Lily Title in here Section 12Title in here section0 Title in here section2Title in here section1 ……… Title in here Board 0 Board 1 Title in here Board n……… ……… -Traversal catalog links to get the content; -Automatic link to Next Page and do the routine job. tips Miner策略：Regex 34 Use HtmlParser To get Tags’ Content Extract Info by regex Store in a designed pattern [Each post will be stored in a line as the pattern blew] URL’/007’hot’/007’auhtor’/007’title’/007’content 建立索引 35 Run a series of Map/Reduce operations to generate Inverted Indices with rank and position info. Indexing Process Txt_Filter Partition Index Table Inverted Index Index For Indices 倒排索引：Posting Info 36 1.TF-IDF (Term Frequency-Inverse Document Frequency): 2.Positions info do not need any calculation. They can be record as a Integer Pair like(StartIndex, EndIndex). Posting Info •| D | : total number of documents in the corpus • : number of documents where the term ti appears (that is ) Target of Web Retrieval Interface 37 Make an Interface which accept user’s query and response search results. 1. Restrict the query string; 2. Sort search result dynamically; 3. Response results page by page. Web Retrieval Interface Javascript+HTML Tomcat+Servlet Technics: Sort Pages 38 Term 0 Term 2 Term 1 Here is a demo. Doc1 10 Doc3 90 Doc7 20 Query String Word Segment Doc2 20 Doc7 80 Doc5 15 Doc3 05 Doc2 40 Doc6 40 Merge Rank Again Doc7 100 Doc3 95 Doc6 40 Doc2 40 Doc5 15 Doc1 10 优化 39 a)For each term only top 1500 DID are reserved at most. b)Use TreeMap to sort.. Reduce Sort Time Reduce I/O operations ……Cache Strategy Optimization measures in different areas. a)Response Page is created dynamically. b)Each time return 10 records. .......... a) Put some hot Inverted Index file in the memory. b) Cache replacement --- LRU Maybe Google & Baidu has done... 40 Parallelly Word Segment User's query Rank 3.A better rank strategy :To describe the relationship between a token and DID precisely 4.Record each user's query string; a) feed back to Word Segment b) Provide remind function.(By input change event) 1. Search Stuff parallelly 2. An outstanding Word Segment Algorithm ……. …… 展示 41 其它MapReduce应用案例 ¨ 大规模基因序列比对 ¨ 大规模城市路径规划 ¨ 大规模重复文档检测 ¨ 基于内容的并行化图像检索算法与引擎 ¨ 大规模微博传播分析 ¨ 城市智能交通综合应用 ¨ …… 42 THANK YOU","libVersion":"0.3.2","langs":""}