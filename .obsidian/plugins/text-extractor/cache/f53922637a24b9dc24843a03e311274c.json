{"path":"docs/学校课程/归档课程/大数据/课件/20 Spark Advanced Programming (II).pdf","text":"Spark高级编程 (II) 摘要 ¨ Spark Streaming ¨ Spark Structured Streaming ¨ GraphX 摘要 ¨ Spark Streaming ¨ Spark Structured Streaming ¨ GraphX Spark Streaming 4 Spark Streaming makes it easy to build scalable fault-tolerant streaming applications. 架构 5 工作原理 ¨ Spark Streaming将流式计算分解成一系列短小的批处理作业，具 有如下特性： ¤ 能线性扩展至超过数百个节点； ¤ 实现亚秒级延迟处理； ¤ 可与Spark批处理和交互式处理无缝集成； ¤ 提供了一个简单的API实现复杂的算法； ¤ 更多的网络流方式支持，包括Kafka、Flume、Kinesis、Twitter、ZeroMQ 等。 6 DStream抽象 ¨ DStream (Discretized Stream, 离散流)：连续的数据流，由一系列 RDDs组成。 7 DStream抽象 ¨ DStream的核心思想是将计算作为一系列较小时间间隔的、状态 无关的、确定批次的任务，每个时间间隔内接收到的输入数据被 可靠地存储在集群中，作为它的一个输入数据集。当某个时间间 隔完成，将对相应的数据集并行地进行Map、Reduce和groupBy等 操作，产生中间数据或输出新的数据集，并存储在RDD中。任务 间的状态可以通过RDD重新计算，得益于计算任务被分解成一系 列的小任务，用户可以在合适的粒度上呈现任务间的依赖关系。 8 DStream抽象 ¨ 两类操作： ¤ 转换操作：生成一个新的DStream ¤ 输出操作：把数据写入外部系统中 ¨ 增加了与时间相关的新操作，比如滑动窗口 9 简单的例子 ¨ 例：从监听TCP套接字的数据服务器获取文本数据，然后计算文本中包含的单 词数。 10 简单的例子 ¨ 例：从监听TCP套接字的数据服务器获取文本数据，然后计算文本中包含的单 词数。 11 抽象 ¨ DStream抽象 12 输入源 ¨ 每一个输入流DStream和一个Receiver对象关联，这个Receiver从源中获取数据， 并将数据存入内存中进行处理。 ¨ 输入源 ¤ 基本源：在StreamingContext API中直接使用，例如文件系统、套接字连接、Akka的actor等。 ¤ 高级源：包括Kafka，Flume，Twitter等，需要通过额外的类来使用。 ¨ 多个数据流à多个Receiver，要分配足够的核（如果是本地运行，那么是线程） 用以处理接收的数据并且运行receiver是非常重要的 13 DStream操作 ¨ 转换操作：允许在DStream运行任何RDD-to-RDD函数，比如map, flatMap, filter, reduce, join等 ¨ 状态操作 ¤ updateStateByKey：不断用新信息更新它的同时保持任意状态 ¤ 窗口操作：允许在一个滑动窗口数据上应用transformation算子，需制定两个 参数：窗口长度（窗口的持续时间）和滑动的时间间隔（窗口操作执行的 时间间隔） 14 DStream操作 15 DStream操作 16 DStream操作 ¨ 输出操作 17 DStream操作 ¨ 缓存及持久化 ¤ persist() ¤ DStream的持久化策略是将数据序列化在内存中。 ¤ 基于窗口或状态的操作，如reduceByWindow、reduceByKeyAndWindow 和updateStateByKey，Dstream都会自动持久化在内存中，无须显式调 用persist()方法。 ¤ 通过网络接收的流数据默认采取保存两份序列化后的数据在两个不同 的节点上的持久化策略，从而实现容错。 18 Checkpointing机制 ¨ Metadata checkpointing：保存流计算的定义信息到容错存储系统如 HDFS中。这用来恢复应用程序中运行worker的节点的故障。元数据 包括： ¤ Configuration ¤ DStream operations ¤ Incomplete batches ¨ Data checkpointing：保存生成的RDD到可靠的存储系统中，这在有 状态transformation（如结合跨多个批次的数据）中是必须的。有状 态的transformation的中间RDD会定时存储到可靠存储系统中。 19 Checkpointing配置 ¨ 在容错、可靠的文件系统（HDFS、S3等）中设置一个目录用于保存checkpoint 信息。 ¤ streamingContext.checkpoint(checkpointDirectory) 20 Spark Streaming编程 ¨ 首先创建StreamingContext： #方法一： val conf = new SparkConf().setAppName(appName).setMaster(master); val ssc = new StreamingContext(conf, Seconds(1)); #方法二：可以使用已有的SparkContext来创建 val sc = new SparkContext(conf); val ssc = new StreamingContext(sc, Seconds(1)); ¨ 注：appName，是用来在Spark UI上显示的应用名称； master，是一个Spark、Mesos或者Yarn集群的URL，或者是local[*]；batch interval可以根据你的应用程序的延迟要求以及可用的集群资源情况来设置。 21 Spark Streaming编程 ¨ 接下来的流程： 1. 通过创建输入DStream来创建输入数据源。 2. 通过对DStream定义transformation和output算子操作，来定义实时计算 逻辑。 3. 调用StreamingContext的start()方法，来开始实时处理数据。 4. 调用StreamingContext的awaitTermination()方法，来等待应用程序的终 止。可以使用CTRL+C手动停止，或者就是让它持续不断的运行进行 计算。 5. 也可以通过调用StreamingContext的stop()方法，来停止应用程序。 22 Spark Streaming编程 ¨ 注意事项： 1. 只要一个StreamingContext启动之后，就不能再往其中添加任何计算逻辑了。比如执行 start()方法之后，还给某个DStream执行一个算子。 2. 一个StreamingContext停止之后，是肯定不能够重启的，调用stop()之后，不能再调用start()。 3. 一个JVM同时只能有一个StreamingContext启动，在你的应用程序中，不能创建两个 StreamingContext。 4. 调用stop()方法时，会同时停止内部的SparkContext，如果不希望如此，还希望后面继续使 用SparkContext创建其他类型的Context，比如SQLContext，那么就用stop(false)。 5. 一个SparkContext可以创建多个StreamingContext，只要上一个先用stop(false)停止，再创建 下一个即可。 23 输入源 ¨ 套接字 val lines = ssc.socketTextStream(\"localhost\", 9999) ¨ 文件流 val logData = ssc.textFileStream(logDirectory) val data = ssc.fileStream[KeyClass, ValueClass, InputFormatClass] (dataDirectory) ¨ 附加数据源 ¤ Apache Kafka ¤ Twitter ¤ Amazon Kinesis ¤ Apache Flume 24 Apache Kafka ¨ Apache Kafka是一个分布式流处理平台。用于构建实时的数据管 道和流式的app。它可以水平扩展，高可用，速度快，并且已经 运行在数千家公司的生产环境。 ¨ 流处理平台的三种特性 ¤ 可以让你发布和订阅流式的记录。这一方面与消息队列或者企业消息 系统类似。 ¤ 可以储存流式的记录，并且有较好的容错性。 ¤ 可以在流式记录产生时就进行处理。 25 Apache Kafka 26 Apache Kafka ¨ Kafka维护按类区分的消息，称为主题（topic） ¨ 生产者（producer）向Kafka的主题发布消息 ¨ 消费者（consumer）向主题注册，并且接收发布到这些主题的消 息 ¨ Kafka以一个拥有一台或多台服务器的集群运行着，每一台服务 器称为broker ¨ 从高层来说，生产者（producer）通过网络发消息到Kafka集群， 而Kafka集群则以下面这种方式对消费者进行服务。 27 Apache Kafka ¨ 步骤 1. 运行zookeeper服务器 2. 运行kafka服务器 3. 创建topic 4. 查看topic是否存在 5. 创建producer 6. 创建consumer（测试） 7. 提交Spark Streaming作业 28 Spark Streaming + Kafka 29 Spark Streaming + Kafka ¨ Linking ¤ groupId = org.apache.spark ¤ artifactId = spark-streaming-kafka-0-10_2.12 ¤ version = 3.0.1 ¨ 编程 ¤ 通过KafkaUtils对象创建出Dstream； ¤ 由于KafkaUtils可以订阅多个主题，因此它创建出的Dstream由成对的主题和消息组成； ¤ 要创建一个流数据，需要使用StreamingContext实例，一个由逗号隔开的Zookeeper主机列表 字符串、消费者组的名字（唯一名字），以及一个从主题到针对这个主题的接收器线程数 的映射表来调用createStream()方法。 30 Spark Streaming + Kafka … Map<String, Integer> topicMap = new HashMap<>(); String[] topics = args[2].split(\",\"); for (String topic: topics) { topicMap.put(topic, numThreads); } JavaPairReceiverInputDStream<String, String> messages = KafkaUtils.createStream(jssc, args[0], args[1], topicMap); JavaDStream<String> lines = messages.map(Tuple2::_2); JavaDStream<String> words = lines.flatMap(x -> Arrays.asList (SPACE.split(x)).iterator()); JavaPairDStream<String, Integer> wordCounts = words.mapToPair(s -> new Tuple2<>(s, 1)).reduceByKey((i1, i2) -> i1 + i2); 31 Spark Streaming + Kafka ¨ Usage: JavaKafkaWordCount <zkQuorum> <group> <topics> <numThreads> ¤ <zkQuorum> is a list of one or more zookeeper servers that make quorum ¤ <group> is the name of kafka consumer group ¤ <topics> is a list of one or more kafka topics to consume from ¤ <numThreads> is the number of threads the kafka consumer should use ¨ $ bin/run-example org.apache.spark.examples.streaming.JavaKafkaWordCount zoo01,zoo02, zoo03 my-consumer-group topic1,topic2 1 32 批量计算 vs 流式计算 ¨ 批量和流式处理数据粒度不一样，批量每次处理一定大小的数据块（输入一般 采用文件系统），一个task处理完一个数据块之后，才将处理好的中间数据发 送给下游。流式计算则是以record为单位，task在处理完一条记录之后，立马 发送给下游。 33 批量计算 vs 流式计算 ¨ 区别 ¤ 数据处理单位 n 批量计算按数据块来处理数据，每一个task接收一定大小的数据块 n 流式计算的上游算子处理完一条数据后，会立马发送给下游算子，所以一条数据从进入 流式系统到输出结果的时间间隔较短 ¤ 数据源 n 批量计算通常处理的是有限数据（bound data），数据源一般采用文件系统，而流式计 算通常处理无限数据（unbound data），一般采用消息队列作为数据源。 ¤ 任务类型 n 批量计算中的每个任务都是短任务，任务在处理完其负责的数据后关闭，而流式计算往 往是长任务，每个worker一直运行，持续接受数据源传过来的数据。 34 批量计算 vs 流式计算 ¨ 离线=批量？实时=流式？ ¤ 离线和实时应该指的是：数据处理的延迟；批量和流式指的是：数据 处理的方式。两者并没有必然的关系。事实上Spark streaming就是采 用小批量（batch）的方式来实现实时计算。 35 流式计算框架 ¨ Apache Storm ¨ Apache Spark Streaming ¨ Apache Flink 36 流式计算框架 ¨ Apache Storm 37 流式计算框架 ¨ Apache Spark Streaming 38 流式计算框架 ¨ Apache Flink 39 Comparison 40 摘要 ¨ Spark Streaming ¨ Spark Structured Streaming ¨ GraphX Spark Structured Streaming 42 Spark Structured Streaming makes it easy to build streaming applications and pipelines with the same and familiar Spark APIs. Spark Structured Streaming 43 Spark Streaming vs. Structured Streaming ¨ Spark Streaming ¤ Spark Streaming是Spark最初的流处理框架，使用了微批的形式来进行 流处理。 ¤ 提供了基于RDDs的Dstream API，每个时间间隔内的数据为一个RDD， 源源不断对RDD进行处理来实现流计算. ¨ Spark Structured Streaming ¤ Spark 2.X出来的流框架，采用了无界表的概念，流数据相当于往一个 表上不断追加行。 ¤ 基于Spark SQL引擎实现，可以使用大多数Spark SQL的function 44 区别 ¨ 流模型 ¤ Spark Streaming采用微批的处理方法。每一个批处理间隔的为一个批，也就 是一个RDD，我们对RDD进行操作就可以源源不断的接收、处理数据。 ¤ Structured Streaming将实时数据当做被连续追加的表。流上的每一条数据都 类似于将一行新数据添加到表中。 45 每隔1秒从输入源 获取数据到Input Table，并触发 Query计算，然后 将结果写入Result Table，之后根据 指定的Output模式 进行写出。 区别 ¨ RDD、DataFrame、DataSet ¤ Spark Streaming的DStream编程接口是RDD。 ¤ Structured Streaming使用DataFrame、DataSet的编程接口，处理数据时可以 使用Spark SQL中提供的方法，数据的转换和输出会变得更加简单。 46 区别 ¨ Process Time vs. Event Rime ¤ Process Time：流处理引擎接收到数据的时间 ¤ Event Time：事件真正发生的时间 ¤ Spark Streaming由于其微批的概念，会将一段时间内接收的数据放入一个批 内，进而对数据进行处理。划分批的时间是Process Time，而不是Event Time， Spark Streaming没有提供对Event Time的支持。 ¤ Structured Streaming提供了基于事件时间处理数据的功能，如果数据包含事 件的时间戳，就可以基于事件时间进行处理。 ¨ Structured Streaming的continuous mode是实时处理的，只要一有数 据就会进行处理，时延基本在毫秒级别。 47 区别 48 Spark Streaming Structured Streaming 区别 ¨ 可靠性保障 ¤ 两者在可靠性保证方面都是使用了checkpoint机制。checkpoint通过设置检查 点，将数据保存到文件系统，在出现故障的时候进行数据恢复。 ¤ 在Spark Streaming中，如果我们需要修改流程序的代码，在修改代码重新提 交任务时，是不能从checkpoint中恢复数据的（程序就跑不起来），是因为 Spark不认识修改后的程序了。 ¤ 在Structured Streaming中，对于指定的代码修改操作，是不影响修改后从 checkpoint中恢复数据的。 49 区别 ¨ Sink：输出数据写入下游 ¤ Spark Streaming中提供了foreachRDD()方法，通过自己编程实现将每个批的 数据写出。 stream.foreachRDD(rdd => { save(rdd) }) ¤ Structured Streaming自身提供了一些sink(Console Sink、File Sink、Kafka Sink等)， 只要通过option配置就可以使用；对于需要自定义的Sink，提供了 ForeachWriter的编程接口，实现相关方法就可以完成。 // console sink val query = res.writeStream.outputMode(\"append\").format(\"console\").start() ¨ 总结：Structured Streaming有更简洁的API、更完善的流功能、更 适用于流处理。而Spark Streaming更适用于偏批处理的场景。 50 Note ¨ Spark Streaming已成为legacy project，不再更新，推荐使用Spark Structured Streaming 51 摘要 ¨ Spark Streaming ¨ Spark Structured Streaming ¨ GraphX GraphX 53 GraphX is Apache Spark's API for graphs and graph-parallel computation. GraphX 54 GraphX ¨ GraphX是Spark中用于图和图并行计算的组件。 ¨ GraphX通过扩展Spark RDD引入一个新的图抽象，一个将有效信息 放在顶点和边的有向多重图。 ¨ GraphX公开了一系列基本运算，以及一个优化后的Pregel API的变 形。包括越来越多的图形计算和builder构造器，以简化图形分析任 务。 ¨ 在Spark之上提供了一站式解决方案，可以方便且高效地完成图计 算的一整套流水作业。 55 GraphX核心抽象 ¨ 弹性分布式属性图（Resilient Distributed Property Graph），一种点和边都带属 性的有向多重图。它扩展了Spark RDD的抽象，有Table和Graph两种视图，而 只需要一份物理存储。两种视图都有自己独有的操作符，从而获得了灵活操作 和执行效率。 56 GraphX框架 57 图处理流水线 58 Preprocessing Compute Post Proc. < / >< / >< / > XML Raw Data ETL Slice Compute Repeat Subgraph PageRankInitial Graph Analyze Top Users 图处理流水线 59 图处理流水线 60 两种视图 ¨ 对Graph视图的所有操作，最终都会转换成其关联的Table视图的RDD操作来完成。这样对一个 图的计算，最终在逻辑上，等价于一系列RDD的转换过程。因此，Graph最终具备了RDD的3个 关键特性：Immutable、Distributed和Fault-Tolerant，其中最关键的是Immutable（不变性）。逻 辑上，所有图的转换和操作都产生了一个新图；物理上，GraphX会有一定程度的不变顶点和 边的复用优化，对用户透明。 ¨ 两种视图底层共用的物理数据，由RDD[VertexPartition]和RDD[EdgePartition]这两个RDD组成。点 和边实际都不是以表Collection[tuple]的形式存储的，而是由VertexPartition/EdgePartition在内部 存储一个带索引结构的分片数据块，以加速不同视图下的遍历速度。不变的索引结构在RDD转 换过程中是共用的，降低了计算和存储开销。 61 两种视图 62 • Table视图将图看成Vertex Property Table和Edge Property Table等的组合，这些 Table继承了Spark RDD的API(filter, map等)。 • Graph视图上包括reverse/subgraph/mapV(E)/joinV(E)/mrTriplets等操作。 GraphX编程 ¨ 属性图是一个用户定义顶点和边的有向多重图。 ¨ 有向多重图是一个有向图，它可能有多个平行边共享相同的源顶点 和目标顶点。 ¨ 多重图支持并行边的能力简化了有多重关系的建模场景。每个顶点 是由具有64位长度的唯一标识符（VertexID）作为主键。GraphX没 有对顶点添加任何顺序的约束。同样，每条边具有相应的源顶点和 目标顶点的标识符。 ¨ 属性表的参数由顶点（VD）和边（ED）的类型决定。 63 GraphX编程 64 GraphX的图操作 ¨ 构造图 ¤ 通过Graph Object构造 ¤ 通过Graph Builder构造 65 GraphX的图操作 ¨ GraphLoader.edgeListFile提供了一种从磁盘上边的列表载入图的 方式。 66 GraphX的图操作 67 GraphX的图操作 ¨ 属性操作 ¨ 转换操作 ¨ 结构操作 ¨ 关联操作 ¨ 聚合操作 ¨ 缓存操作 68 Table Operators ¨ Table (RDD) operators are inherited from Spark: 69 map filter groupBy sort union join leftOuterJoin rightOuterJoin reduce count fold reduceByKey groupByKey cogroup cross zip sample take first partitionBy mapWith pipe save ... Graph Operators 70 Graph Operators 71 Graph Operators 72 Triplets Join Vertices and Edges ¨ The triplets operator joins vertices and edges: 73 TripletsVertices Edges B A C D A B A C B C C D A BA B A C B C C D A BA B 常用图算法 ¨ PageRank算法 ¨ 三角形计数算法 ¨ 连接分量算法 74 ¨ GraphX自带PageRank的静态和动态实现，放在PageRank对象中。静态的 PageRank运行固定数量的迭代，而动态的PageRank运行直到排名收敛。 PageRank算法 75 三角形计数算法 ¨ 计算通过各顶点的三角形数目，从而提供集群的度。TriangleCount要求边的指 向（srcId<dstId），并使用Graph.partitionBy分割图形。 76 连接分量算法 ¨ 连接分量算法标出了图中编号最低的顶点所连接的子集。 77 应用场景 ¨ 图谱体检平台 ¨ 多图合并工具 ¨ 能量传播模型 ¨ …… 78 推荐 https://github.com/sryza/aas THANK YOU","libVersion":"0.3.2","langs":""}